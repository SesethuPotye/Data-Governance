# CHAPTER 2 
Overview
In this chapter, we will be:

* Defining data and its relationship to information
* Exploring the role of data in the 21st century
* Moving from data to insights
* Discovering the impact of big data

* Traditionally, organizations operate with limitations (budget, time, etc.). This scarcity is a fundamental principle in economics.
  
* However, the situation with data is quite different. Most organizations today have vast amounts of data collected through their activities, products, services, and interactions with customers and partners. This abundance of data, rather than limitations, presents a new challenge.
  
* Organizations are now faced with questions about harnessing the potential of this data, protecting it, and simply managing its sheer volume.
  
* We're living in the age of big data, and effectively managing this data can significantly improve an organization's performance and profitability.


# Defining Data

* Data refers to collections of digitally stored units, in other words, stuff that is kept on a computing device. These units represent something meaningful when processed for a human or a computer. Single units of data are traditionally referred to as datum and multiple units as data. However, the term data is often used in singular and plural contexts.

* Data is also defined based on its captured format. Specifically, at a high level, it falls into one of the following categories:

# Structured:
Data that has been formatted to a set structure; each data unit fits nicely into a table in a database. It’s ready for analysis. Examples include first name, last name, and phone number.

# Unstructured:
Data that are stored in a native format must be processed to be used. Further work is required to enable analysis. Examples include email content and social media posts.
# Semi-structured: 
Data that contains additional information to enable the native form

# Welcome to The Zettabyte Era

* In the past, the term "zettabyte" wasn't commonly used because data wasn't as prevalent.
  
* With the digital age and our increasingly connected world, the amount of data being created and stored has grown tremendously.
  
* To handle this massive amount of data, we've had to bring back the term "zettabyte" as a unit to measure this vastness.
  

 # The qualitative and quantitative nature of data types. 
 ![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/c76a3386-c841-4533-8f8c-4424e668e1e2)

 
* Zettabyte Era: We're in a time where data is measured in zettabytes - a vast unit equal to 1,000,000,000,000,000,000,000 bytes (written as 10^21).

* Explosive Data Growth: By 2020, we created 64 zettabytes of data, and this keeps growing rapidly. Projections estimate reaching over 100 zettabytes by 2023 and potentially doubling in just a few years.
  
* Perspective on Size: Imagine needing a billion terabyte drives to store just one zettabyte!
  
* Technical Breakdown: A zettabyte is made up of bytes, which are collections of 8 bits (0s and 1s) - the fundamental building blocks for storing data on computers.
  
* Future of Data Measurement: As data keeps growing, we might need even larger terms like yottabyte and brontobyte to measure it.

# Quantification of Data Storage

![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/60cfd1e1-1bc2-4b24-86a9-67263944dc80)




# Examples of Data Volumes
![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/bea1e209-c49f-46c2-a6e3-c7cb03f8f601)

Managing a small amount of data can have challenges, but managing data at scale is materially more challenging. If you’re going to glean value from data, it has to be understood and managed in specific ways.

# From Data to Insight

* Simply collecting and storing data isn't valuable. It needs to be done with a specific purpose or intended future use in mind.
  
* There might be some rare exceptions where collecting data without an immediate use case makes sense, but this shouldn't be the norm.
  
* In most cases, organizations collect data because it's essential for a particular goal or function.

# The Differences Between Data and Information

![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/c4323b57-c8fc-4a94-97aa-6880101a9d19)


* Data is the raw, unprocessed information we collect.
* Information is data put into context, making it more meaningful.
* Knowledge is what you can do with information. It's actionable and allows you to understand how to use information for a specific purpose. This is where the saying "knowledge is power" comes into play.
* Wisdom builds upon knowledge. It involves applying reasoning, values, and broader life experiences to make sound judgments about the validity and application of knowledge in different situations. Not all knowledge is wisdom, but all wisdom includes knowledge.
* Insight is the deepest level of understanding. It combines knowledge and wisdom to see something in a new light and gain a deeper understanding. It allows you to think or see things differently.


# To summarize, consider the following:

* Harry Styles is data.
  
* The fact that Harry Styles is a singer and was in the group, One Direction, is information.
  
* The fact that Harry Styles has aspirations to become a solo artist and is looking for a record deal is knowledge.
  
* The fact that One Direction was a very successful band with talented and popular individuals and knowing that Harry Styles is a creative artist who now wants a solo record deal is wisdom.
  
* Ensuring that Columbia Records make the decision to sign Harry Styles before anyone else does is insight.

# Below illustrates the journey from data to insight.

![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/da1020a5-ab58-441b-b390-4fcd95f3f937)


Another depiction of the data-information-knowledge-wisdom (DIKW) hierarchy as a pyramid to manage knowledge is illustrated below:

![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/58e9e9ac-f4f8-494d-9949-a138ec50f36a)


* Different organizations can have varying results even when analyzing the same data set.
* There's no guaranteed path to the "best" outcome, regardless of the tools, processes, or skills used.
* However, good data governance practices can significantly improve the results you get from your data.

# The Role of Data in the 21st Century

* Data's Consistent Value: Data has always played a crucial role in helping us understand the world, make better decisions, and solve problems.
  
* The Data Explosion: Since the mid-20th century, the rise of computers significantly increased the volume, quality, and accessibility of data.
  
* The Information Age: The internet's arrival in the mid-90s made information readily available, fulfilling the vision of "information at your fingertips."
  
* Democratization of Information: Bill Gates' vision of accessible information for everyone further emphasized the growing importance of data in the late 1980s.

* Data Deluge: We're producing more data than we can manage. This vast data, with its depth, breadth, and quality, is transforming various aspects of our lives.
* Impact on Industries and Cities: This data revolutionizes the tools and capabilities of our industries and cities.
* Societal Shifts: It's fundamentally changing how we learn, socialize, and entertain ourselves.
* Heightened Risks: Cybersecurity threats are no longer minor inconveniences. A cyberattack can now cause significant financial losses within a short time frame.


# Data-Driven Decision-Making

* Data for Personal Choices: We use data in everyday decisions, like reading online reviews to choose a restaurant. This data is valuable to both consumers (informing decisions) and businesses (gaining customer feedback).
  
* Data for Complex Decisions: Businesses use vast amounts of data to make complex choices, like entering new markets. Analyzing this data helps make well-informed decisions and avoid costly mistakes.
  
* Data Makes a Difference: Access to good data and the ability to analyze it are crucial for making sound decisions. Without this, businesses risk making poor choices.

IMPORTANT
* Good Data Makes Good Decisions: Having a lot of data is helpful, but it needs to be accurate and reliable (good quality) to make sound decisions.
  
* Quality Over Quantity: Bad data can lead to poor choices and challenges.
21st Century Data Abundance: We have a lot of data available now, but ensuring its quality requires specific actions.
  
* Data Governance for Quality: Data governance practices are essential for achieving good quality data.

# Data as The New Oil

* Data as the New Oil: This quote by Clive Humby emphasizes that data, like oil, is a valuable resource that fuels modern economies.
  
* Data Needs Processing: Just as oil needs refining to be useful, data requires processing and analysis to unlock its true potential.
  
* Extracting Value from Data: This processing involves organizing and analyzing data to identify patterns, make informed decisions, solve problems, and feed other systems.

# Without these additional steps of organizing and analyzing, oil and data are similar in that they are notably messy and unusable in their raw form.

the below passage compares data to oil and highlights its importance in the digital age:

* Data Fuels Digital Economies: Similar to how oil powered industrial economies, data is the driving force behind the digital economies of the 21st century.
  
* Tech Giants Lead the Way: Companies like Facebook and Google, with their vast data resources, are major players in this data-driven economy.
  
* Data Revolution Across Industries: Data and digitalization are transforming every sector, from banking and government to countless others.
  
* Data as a Profit Engine: Organizations are shifting data management from a cost to a profit center, using data to power their businesses and generate revenue streams.
  
* Power Imbalance and Risks: Just like oil, control of large amounts of valuable data grants immense power. The historical dependence on oil highlights potential risks associated with a few big players managing personal data.

# Data Ownership

* Effective management requires assigning clear responsibility. This is done through job descriptions and project roles.
  
* Similarly, data accountability is crucial. Every data set within an organization needs to have someone responsible for it.

* This concept shouldn't be surprising, as it aligns with established management practices.

# The passage defines data ownership and the varying levels of control it entails:

* Data Ownership refers to the rights and control exercised over a particular data set by ana individual, team, or organization.
* Spectrum of Control: This control can range from basic oversight to strict, legally binding rules.
* Example: Intellectual Property: Data related to intellectual property (copyrights, trade secrets) will typically have strong ownership protections, including restrictions on access, usage, and purpose.


# DATA ARCHITECTURE

* Technology is Essential: Nearly every organization relies on technology to operate and deliver products or services. They can be considered technology businesses in this sense.
  
* Enterprise Architecture (EA): This framework helps organizations design, plan, and implement the right technology solutions (systems, policies, projects) aligned with their overall business strategy. It uses established standards and principles.
  
* Data Architecture as a Subset of EA: Just like EA focuses on the bigger picture of technology aligning with strategy, data architecture focuses specifically on how data is designed and managed to support both EA and the overall business goals.
  
* Data Architecture Blueprint: In simpler terms, data architecture is the agreed-upon plan for how data structures and management practices will support the organization's functions and technologies.

IMPORTANT
* Strong Architectures, Smooth Operations: When both EA and data architecture are implemented effectively, organizations can function more efficiently and adapt to changing circumstances (internal or external).
  
* The Downside of Weak Architectures: Poor or missing architectures can hinder digital transformation efforts, introduce complexity, and increase the risk of failure.
  
* Working Together: By design, these architectures work together to ensure data supports the organization's technological needs and overall business strategy.

# fIVE KEY OBJECTIVES OF DATA ARCHITECTURE

1. Data Accessibility: Ensuring the right people have access to the data they need to do their jobs, while also controlling access for security purposes.

2. Data Usability: Simplifying how people can find, understand, and use data within the organization.
   
3. Data Protection: Implementing safeguards to protect data in accordance with organizational policies and legal requirements.
   
4. Data Standardization: Establishing consistent data formats and definitions to ensure clear and consistent data use across the organization.
   
5.Data Efficiency: Optimizing data flows to eliminate redundancy, bottlenecks, and wasted resources.

# The passage highlights the connection between data governance and data architecture:

* Data Architecture Reflects Governance: A well-defined and functioning data architecture indicates an organization prioritizes data. It's managed as a valuable asset with controls to ensure alignment with business needs.
  
* Shared Responsibility: Similar to enterprise architecture, data architecture isn't solely a technical concern. It's a responsibility shared across the organization.
  
* Data Flow and Silos: In medium to large organizations, data needs to seamlessly flow across departments (e.g., sales and product development) and serve diverse users in various formats. Data architecture helps achieve this.

# THE LIFE CYCLE OF DATA
All data goes through phases during its lifecycle
![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/f05e9dab-01bf-4121-a02a-fc97466299d3)

FIVE STAGES OF THE DATA LIFECYCLE:

1. Creation: This is the origin of data. It can be generated manually or automatically, internally or externally, through various activities and system interactions.
   
2. Storage: Once created and intended for future use, data needs to be stored. This often involves databases residing on local drives, servers, or cloud storage solutions.
   
3. Usage: Data is typically collected and stored for a reason - to be used later, possibly for analysis. Before use, data may require processing to cleanse errors, convert formats, or manage access permissions.
   
4. Archiving: Here, data identified as inactive gets moved to a long-term storage system outside the active environment. This archived data can still be retrieved and used if needed in the future.
   
5. Destruction: While some might prefer to hold onto everything indefinitely, there comes a point when data destruction is necessary. This could be due to regulations, policies, or simply no longer needing the data. Destruction ensures data becomes inaccessible and unreadable, sometimes involving physical destruction of storage devices.

# IMPORTANCE! 

* Data Lifecycle Stages: Data exists in various states throughout its lifecycle (creation, storage, usage, archival, destruction).
  
* Stage-Specific Treatment: Data requirements and handling differ depending on the lifecycle stage. For instance, security measures for actively used data will be stricter compared to archived data.
  
* Data Governance Impact: Understanding the data lifecycle is crucial for data governance as it helps determine appropriate handling practices at each stage.
  

# UNDERSTANDING THE IMPACT OF BIG DATA

* Data collection has been around for a long time, even before computers.
People have been keeping records for thousands of years, like the Romans using ledgers.

* The 20th century saw advancements in data storage due to the Cold War.
  
* The space race, a part of the Cold War, further accelerated innovation in computing and communication.

# The Role of The U.S. Census in The Information Revolution

* The massive task of processing census data in the 1880s (taking 8 years!) led to the invention of data processing machines.
  
* The Tabulating Machine Company (later IBM) created a system using punch cards to represent and process census information.
  
* This innovation in data processing laid the foundation for future advancements and the rise of the Information Age.
  
* The success of data processing for the census led to its use in other areas, further accelerating the information revolution.

# Defining Big Data(THE FIVE VS THAT DEFINE BIG DATA)

* Volume: The massive amount of data being generated requires new approaches to handle it.
  
* Variety: The ever-increasing number of data formats demands new methods for handling, analyzing, and securing this data.
  
* Velocity: Data is constantly being created and transferred at ever-growing speeds.
  
* Variability: The unpredictable nature of data creation and flow makes it challenging to manage.
  
* Veracity: The accuracy and quality of vast amounts of data can vary significantly, posing a problem for data management.


# Drivers of Big Data

Eric Schmidt, former Google CEO, in 2003. He claimed that the amount of data created globally every two days surpassed the total data created throughout human history up to that point. This emphasizes the explosive growth of data generation in the early 21st century.

# THE EXISTANCE OF BIG DATA 

* The explosion of smartphones and apps
* The Internet of Things (IoT) with its billions of connected devices
* The massive amounts of social media content like cat videos

In a nutshell, big data grew explosively in the third decade of the 21st century, reaching zettabytes in size.

#EXAMPLE OF A DAIGRAM SHOWING DATA GROWTH IN ZETTABYTES FROM 2010 TO 2025
![image](https://github.com/SesethuPotye/Data-Governance/assets/162969678/33399403-bc72-4527-aff0-156b39c8507f)


* In 2021, 79 zettabytes of data were created globally.
  
* This amount is expected to reach 180 zettabytes by 2025.
  
* The point is that future readers (e.g., in 2040) might find these numbers insignificant, similar to how 32GB phone storage seemed massive in 2015 but feels small today.
  
* This emphasizes the exponential growth of data generation.

# CONSEQUENCES OF BIG DATA

# IMPORTANT
* Big data statistics might seem impressive, but there's more to the story.
* Key challenges exist with big data quality, accessibility, and analysis.
* Up to 80% of data is unstructured, making it difficult to handle for most organizations.
* Data can also be duplicated or bad (containing errors), posing further challenges.

Despite the challenges mentioned earlier, big data offers significant benefits:

* It provides valuable insights for organizations of all kinds.
* It fuels innovation across various fields, from self-driving cars to efficient supply chains.

# WHAT IS SMALL DATA? 

All this talk about big data might suggest that small amounts of data just aren’t as interesting or valuable. I don’t want to suggest that, as it would be wrong.

# IMPORTANT
* Big data dominates decision-making in the digital economy, but small data sets also play a crucial role.
* Examples include spreadsheets, short surveys, and personal to-do lists.
* While less glamorous than big data, small data can be equally valuable in specific situations.

# BIG DATA CAN BE ANSWERED IN SMALL DATA
* Big questions can be answered by analyzing smaller datasets.
* Big data often needs to be broken down into smaller chunks for better comprehension.
* In some cases, using smaller, well-organized datasets might be the only way to make sense of massive amounts of data.

# ENTER THE REALM OF SMART DATA

* Big data can be overwhelming due to its vast volume, variety, and speed (velocity).

* Smart data tackles this by applying processes to big data, making it more usable for specific purposes.

* This allows for targeted marketing campaigns or real-time analytics in manufacturing, for instance.

* Smart data leverages new tools like AI to identify patterns and extract relevant data from unstructured big data sets.

* AI helps reduce processing time, errors, and enables creation of more focused data subsets.
* Additionally, smart data solutions are often implemented at the data collection stage, rather than as an afterthought.































